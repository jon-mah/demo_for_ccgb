param_string_low = as.numeric(param_string_low)
neugamma_scale_low = param_string_low[3]
# neugamma_dfe_bound_high = compute_dfe_height(shape=neugamma_shape, scale=neugamma_scale_high)
# neugamma_dfe_bound_low = compute_dfe_height(shape=neugamma_shape, scale=neugamma_scale_low)
neugamma_dfe_dist_high = rgamma(100000, shape=neugamma_shape, scale=neugamma_scale_high)
neugamma_dfe_dist_low = rgamma(100000, shape=neugamma_shape, scale=neugamma_scale_low)
zeroed_sites = as.integer(100000 * neugamma_proportion)
neugamma_dfe_dist_high[1:zeroed_sites] = 1e-06* 1.1
neugamma_dfe_dist_low[1:zeroed_sites] = 1e-06 * 1.1
dfe_df = data.frame(gamma_dfe_dist_high,
gamma_dfe_dist_low,
neugamma_dfe_dist_high,
neugamma_dfe_dist_low)
dfe_df[dfe_df < 1e-9] = 1e-9
names(dfe_df) = c('Gamma, mu=6.93E-10', 'Gamma, mu=4.08E-10',
'Neugamma, mu=6.93E-10', 'Neugamma, mu=4.08E-10')
fig = ggplot(melt(dfe_df), aes(x=value, y=..density.., fill=variable)) +
geom_histogram(position='dodge',
breaks=c(0.000000001, 0.00000001,  0.0000001, 0.000001, 0.0001)) +
scale_x_log10() +
ylab('Proportion of sites') +
xlab('Selective Effect') +
theme_bw() + theme(panel.border = element_blank(), panel.grid.major = element_blank(),
panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) +
guides(fill=guide_legend(title="Estimated mutation rate"))
return(fig)
}
plot_core_accessory_dfe = function(input_dfe_file) {
## Reads input DFE from output *inferred_DFE.txt
this_file = file(input_dfe_file) # Open file
on.exit(close(this_file)) # Close when done
# Parse file and string manipulation
param_string_low = readLines(this_file)[5]
# Extract the two floats using regular expression
floats <- str_extract_all(param_string_low, "[+-]?\\d*\\.?\\d+(?:[eE][+-]?\\d+)?")
# Convert the extracted strings to numeric values
gamma_shape <- as.numeric(floats[[1]][1])
gamma_scale_low <- as.numeric(floats[[1]][2])
gamma_dfe_dist_low = rgamma(100000, shape=gamma_shape, scale=gamma_scale_low)
dfe_df = data.frame(gamma_dfe_dist_low)
dfe_df[dfe_df < 1e-15] = 1e-12
dfe_df[dfe_df > 0.5] = 0.5
fig = ggplot(melt(dfe_df), aes(x=value, y=..density.., fill=variable)) +
geom_histogram(position='dodge',
breaks=c(1E-13, 1E-12, 1E-11, 1E-10, 1E-9, 1E-8, 1E-7, 1E-6, 1E-5, 1E-4, 1E-3, 1E-2, 1E-1, 1E0, 1E1),
show.legend = FALSE,
fill='grey') +
# geom_density() +
scale_x_log10(limits=c(1E-13, 1E1)) +
ylab('Proportion of sites') +
xlab('Selective Effect') +
theme_bw() + theme(panel.border = element_blank(), panel.grid.major = element_blank(),
panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"))
return(fig)
}
plot_best_fit_sfs = function(input_data) {
input_data = data.frame(input_data)
colnames(input_data) = c(
'Empirical Synonymous',
'Model Synonymous',
'Empirical Nonsynonymous',
'Model Nonsynonymous',
'Species',
'X.axis')
fig = ggplot(melt(input_data, id=c('Species', 'X.axis')), aes(x=X.axis, y=as.numeric(value), fill=variable)) +
geom_bar(position='dodge2', stat='identity') +
labs(x = "", fill = "") +
xlab('Minor allele frequency') +
ylab('Proportion of segregating sites') +
theme_bw() + theme(panel.border = element_blank(), panel.grid.major = element_blank(),
panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) +
scale_fill_manual(values=c("blue4", "steelblue3", "goldenrod3", "goldenrod1")) +
theme(legend.position="none") +
theme(plot.title = element_text(face = "italic"))
return(fig)
}
plot_best_fit_sfs_3A = function(input_data) {
input_data = data.frame(input_data)
colnames(input_data) = c(
'Empirical Synonymous',
'MLE Synonymous',
'Empirical Nonsynonymous',
'MLE Nonsynonymous',
'Species',
'X.axis')
fig = ggplot(melt(input_data, id=c('Species', 'X.axis')), aes(x=X.axis, y=as.numeric(value), fill=variable)) +
geom_bar(position='dodge2', stat='identity') +
labs(x = "", fill = "") +
ylab('Proportion of segregating sites') +
theme_bw() + theme(panel.border = element_blank(), panel.grid.major = element_blank(),
panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) +
scale_fill_manual(values=c("blue4", "steelblue3", "goldenrod3", "goldenrod1"), name='Site-frequency-spectra') +
# scale_fill_manual(values=c("#cb181d", "#fb6a4a", "blue4", "steelblue3"), name='Site-frequency-spectra') +
theme(legend.position = c(0.72, 0.75)) +
theme(legend.text=element_text(size=10)) +
theme(plot.title = element_text(face = "italic", size=16)) +
theme(axis.text=element_text(size=12),
axis.title=element_text(size=16))
return(fig)
}
plot_best_fit_sfs_3B = function(input_data) {
input_data = data.frame(input_data)
colnames(input_data) = c(
'Empirical Synonymous',
'Model Synonymous',
'Empirical Nonsynonymous',
'Model Nonsynonymous',
'Species',
'X.axis')
fig = ggplot(melt(input_data, id=c('Species', 'X.axis')), aes(x=X.axis, y=as.numeric(value), fill=variable)) +
geom_bar(position='dodge2', stat='identity') +
labs(x = "", fill = "") +
xlab('Minor allele frequency') +
ylab('Proportion of segregating sites') +
theme_bw() + theme(panel.border = element_blank(), panel.grid.major = element_blank(),
panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")) +
scale_fill_manual(values=c("blue4", "steelblue3", "goldenrod3", "goldenrod1")) +
# scale_fill_manual(values=c("#cb181d", "#fb6a4a", "blue4", "steelblue3"), name='Site-frequency-spectra') +
theme(legend.position="none") +
theme(plot.title = element_text(face = "italic", size=16)) +
theme(axis.text=element_text(size=12),
axis.title=element_text(size=16))
return(fig)
}
plot_dfe_grid = function(input) {
species_surface = read.csv(input, header=TRUE)
names(species_surface) = c('shape', 'scale', 'likelihood')
unique_shape = unique(species_surface$shape)
unique_scale = unique(species_surface$scale)
Z = matrix(data=NA, nrow=length(unique_shape), ncol=length(unique_scale))
count = 1
for (i in 1:length(unique_shape)) {
for (j in 1:length(unique_scale)) {
Z[i, j] = species_surface$likelihood[count]
if (species_surface$shape[count] != unique_shape[i]) {
print('break')
} else if (species_surface$scale[count] != unique_scale[j]) {
print('break')
}
count = count + 1
}
}
species_surface = species_surface[order(species_surface$likelihood, decreasing=TRUE), ]
best_params = c(species_surface$shape[1], species_surface$scale[1])
print(best_params)
MLE = max(species_surface$likelihood)
species_surface$likelihood = species_surface$likelihood - MLE
color_breakpoints = cut(species_surface$likelihood, c(-Inf, -3, -1, -0.5, 0))
likelihood_surface_title = paste('MLE @ [', str_trunc(toString(best_params[1]), 8, ellipsis=''), sep='')
likelihood_surface_title = paste(likelihood_surface_title, ', ', sep='')
likelihood_surface_title = paste(likelihood_surface_title, str_trunc(toString(best_params[2]), 8, ellipsis=''), sep='')
likelihood_surface_title = paste(likelihood_surface_title, ']', sep='')
fig = ggplot(species_surface) +
geom_contour_filled(aes(x=shape, y=scale, z=likelihood),
breaks = c(0, -0.5, -1, -3, -Inf)) +
scale_fill_brewer(palette = "YlGnBu", direction=1, name='Log Likelihood') +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black")) +
annotate('point', x=best_params[1], y=best_params[2], color='orange', size=2) +
xlab('Shape')  +
ylab('Scale') +
scale_y_log10()
#ggtitle(likelihood_surface_title)
return(fig)
}
find_dfe_mle = function(input) {
species_surface = read.csv(input, header=TRUE)
names(species_surface) = c('shape', 'scale', 'likelihood')
unique_shape = unique(species_surface$shape)
unique_scale = unique(species_surface$scale)
Z = matrix(data=NA, nrow=length(unique_shape), ncol=length(unique_scale))
count = 1
species_surface = species_surface[order(species_surface$likelihood, decreasing=TRUE), ]
best_params = c(species_surface$shape[1], species_surface$scale[1])
print(best_params)
MLE = max(species_surface$likelihood)
print(MLE)
}
cross_species_dfe_comparison = function(input_A, input_B) {
species_surface_A = read.csv(input_A, header=TRUE)
names(species_surface_A) = c('shape', 'scale', 'likelihood')
unique_shape_A = unique(species_surface_A$shape)
unique_scale_A = unique(species_surface_A$scale)
Z_A = matrix(data=NA, nrow=length(unique_shape_A), ncol=length(unique_scale_A))
count = 1
for (i in 1:length(unique_shape_A)) {
for (j in 1:length(unique_scale_A)) {
Z_A[i, j] = species_surface_A$likelihood[count]
if (species_surface_A$shape[count] != unique_shape_A[i]) {
print('break')
} else if (species_surface_A$scale[count] != unique_scale_A[j]) {
print('break')
}
count = count + 1
}
}
temp_surface_A = species_surface_A[order(species_surface_A$likelihood, decreasing=TRUE), ]
best_params_A = c(temp_surface_A$shape[1], temp_surface_A$scale[1])
ML_A = temp_surface_A$likelihood[1]
species_surface_B = read.csv(input_B, header=TRUE)
names(species_surface_B) = c('shape', 'scale', 'likelihood')
unique_shape_B = unique(species_surface_B$shape)
unique_scale_B = unique(species_surface_B$scale)
Z_B = matrix(data=NA, nrow=length(unique_shape_B), ncol=length(unique_scale_B))
count = 1
for (i in 1:length(unique_shape_B)) {
for (j in 1:length(unique_scale_B)) {
Z_B[i, j] = species_surface_B$likelihood[count]
if (species_surface_B$shape[count] != unique_shape_B[i]) {
print('break')
} else if (species_surface_B$scale[count] != unique_scale_B[j]) {
print('break')
}
count = count + 1
}
}
temp_surface_B = species_surface_B[order(species_surface_B$likelihood, decreasing=TRUE), ]
best_params_B = c(temp_surface_B$shape[1], temp_surface_B$scale[1])
ML_B = temp_surface_B$likelihood[1]
combined_likelihood = species_surface_A$likelihood + species_surface_B$likelihood
comparison_surface = data.frame(species_surface_A$shape, species_surface_A$scale, combined_likelihood)
temp_comparison_surface = comparison_surface[order(comparison_surface$combined_likelihood, decreasing=TRUE), ]
best_params_comparison = c(temp_comparison_surface$species_surface_A.shape[1], temp_comparison_surface$species_surface_A.scale[1])
ML_comparison = temp_comparison_surface$combined_likelihood[1]
independent_sum = ML_A + ML_B
return(ML_comparison - independent_sum)
}
compare_core_accessory_sfs = function(all, core, accessory) {
x_axis = 1:length(all)
input_df = data.frame(proportional_sfs(all),
proportional_sfs(core),
proportional_sfs(accessory),
x_axis)
names(input_df) = c('All genes',
'Core genes',
'Accessory genes',
'x_axis')
p_input_comparison <- ggplot(data = melt(input_df, id='x_axis'),
aes(x=x_axis,
y=value,
fill=variable)) +
geom_bar(position='dodge2', stat='identity') +
labs(x = "", fill = "") +
scale_x_continuous(name='Minor allele frequency in Sample', breaks=x_axis, limits=c(0.5, length(x_axis) + 0.5)) +
ylab('Proportion of segregating sites') +
theme_bw() + theme(panel.border = element_blank(), panel.grid.major = element_blank(),
panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"))
## scale_fill_manual(values=c("darkslateblue", "darkslategrey", "darkturquoise"))
return(p_input_comparison)
}
compare_core_accessory_sfs_count = function(all, core, accessory) {
x_axis = 1:length(all)
input_df = data.frame(all,
core,
accessory,
x_axis)
names(input_df) = c('All genes',
'Core genes',
'Accessory genes',
'x_axis')
p_input_comparison <- ggplot(data = melt(input_df, id='x_axis'),
aes(x=x_axis,
y=value,
fill=variable)) +
geom_bar(position='dodge2', stat='identity') +
labs(x = "", fill = "") +
scale_x_continuous(name='Minor allele frequency in Sample', breaks=x_axis, limits=c(0.5, length(x_axis) + 0.5)) +
ylab('Proportion of segregating sites') +
theme_bw() + theme(panel.border = element_blank(), panel.grid.major = element_blank(),
panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"))
## scale_fill_manual(values=c("darkslateblue", "darkslategrey", "darkturquoise"))
return(p_input_comparison)
}
compare_core_accessory_sfs_syn_ns = function(core_syn, core_nonsyn, accessory_syn, accessory_nonsyn) {
x_axis = 1:length(core_syn)
input_df = data.frame(proportional_sfs(core_syn),
proportional_sfs(core_nonsyn),
proportional_sfs(accessory_syn),
proportional_sfs(accessory_nonsyn),
x_axis)
names(input_df) = c('Core genes (Syn)',
'Core genes (Nonsyn)',
'Accessory genes (Syn)',
'Accessory genes (Nonsyn)',
'x_axis')
p_input_comparison <- ggplot(data = melt(input_df, id='x_axis'),
aes(x=x_axis,
y=value,
fill=variable)) +
geom_bar(position='dodge2', stat='identity') +
labs(x = "", fill = "") +
scale_x_continuous(name='Minor allele frequency in Sample', breaks=x_axis, limits=c(0.5, length(x_axis) + 0.5)) +
ylab('Proportion of segregating sites') +
theme_bw() + theme(panel.border = element_blank(), panel.grid.major = element_blank(),
panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"))+
scale_fill_manual(values=c("blue4", "steelblue3", "goldenrod3", "goldenrod1"))
return(p_input_comparison)
}
compare_core_sfs = function(all, core) {
x_axis = 1:length(all)
input_df = data.frame(proportional_sfs(all),
proportional_sfs(core),
x_axis)
names(input_df) = c('All genes',
'Core genes',
'x_axis')
p_input_comparison <- ggplot(data = melt(input_df, id='x_axis'),
aes(x=x_axis,
y=value,
fill=variable)) +
geom_bar(position='dodge2', stat='identity') +
labs(x = "", fill = "") +
scale_x_continuous(name='Minor allele frequency in Sample', breaks=x_axis, limits=c(0.5, length(x_axis) + 0.5)) +
ylab('Proportion of segregating sites') +
theme_bw() + theme(panel.border = element_blank(), panel.grid.major = element_blank(),
panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"))
## scale_fill_manual(values=c("darkslateblue", "darkslategrey", "darkturquoise"))
return(p_input_comparison)
}
extract_array_length <- function(input_string) {
array_string <- str_extract(input_string, "\\[(.*?)\\]")
num_elements <- length(strsplit(array_string, "[ ,]")[[1]])
return(num_elements)
}
AIC_from_demography = function(input_file) {
## Reads input SFS from output *demography.txt
if(grepl("one_epoch", input_file)) {
k=2
} else if(grepl("two_epoch", input_file)) {
k=4
} else {
k=8
}
this_file = file(input_file)
on.exit(close(this_file))
ll_string = readLines(this_file)[2]
loglik <- as.numeric(str_extract(ll_string, "-?\\d+\\.\\d+"))
return(k - 2*loglik)
}
return_nu_high = function(input) {
species_surface = read.csv(input, header=TRUE)
names(species_surface) = c('index', 'nu', 'tau', 'likelihood')
MLE = max(species_surface$likelihood)
# Task 1: Remove rows with likelihood less than MLE - 3
species_surface <- species_surface[species_surface$likelihood >= MLE - 3, ]
# Task 2: Get the highest nu value from the remaining rows
highest_nu <- max(species_surface$nu)
return(highest_nu)
}
return_nu_low = function(input) {
species_surface = read.csv(input, header=TRUE)
names(species_surface) = c('index', 'nu', 'tau', 'likelihood')
MLE = max(species_surface$likelihood)
# Task 1: Remove rows with likelihood less than MLE - 3
species_surface <- species_surface[species_surface$likelihood >= MLE - 3, ]
# Task 2: Get the highest nu value from the remaining rows
lowest_nu <- min(species_surface$nu)
return(lowest_nu)
}
return_nu_mle = function(input) {
species_surface = read.csv(input, header=TRUE)
names(species_surface) = c('index', 'nu', 'tau', 'likelihood')
species_surface = species_surface[order(species_surface$likelihood, decreasing=TRUE), ]
return(species_surface$nu[1])
}
return_time_high = function(input, sfs_file, theta_file) {
species_surface = read.csv(input, header=TRUE)
names(species_surface) = c('index', 'nu', 'tau', 'likelihood')
MLE = max(species_surface$likelihood)
# Task 1: Remove rows with likelihood less than MLE - 3
species_surface <- species_surface[species_surface$likelihood >= MLE - 3, ]
# Task 2: Get the highest nu value from the remaining rows
highest_tau <- max(species_surface$tau)
# Read the contents of the file into a variable
sfs_lines <- readLines(sfs_file)
# Extract the second line and split it into individual values
sfs_line <- sfs_lines[2]
sfs_vector <- as.numeric(unlist(strsplit(sfs_line, " ")))
allele_sum = sum(sfs_vector)
# Read the contents of the file into a variable
theta_lines <- readLines(theta_file)
# Extract the fifth line
theta_line <- theta_lines[5]
theta <- as.numeric(regmatches(theta_line, regexpr("\\d+\\.\\d+", theta_line)))
mu_low = 4.08E-10
generations_high = 2 * highest_tau * theta / (4 * mu_low * allele_sum)
years = 2 * highest_tau * theta / (4 * 4.08E-10 * allele_sum * 365)
return(years)
}
return_time_low = function(input, sfs_file, theta_file) {
species_surface = read.csv(input, header=TRUE)
names(species_surface) = c('index', 'nu', 'tau', 'likelihood')
MLE = max(species_surface$likelihood)
# Task 1: Remove rows with likelihood less than MLE - 3
species_surface <- species_surface[species_surface$likelihood >= MLE - 3, ]
# Task 2: Get the highest nu value from the remaining rows
lowest_tau <- min(species_surface$tau)
# Read the contents of the file into a variable
sfs_lines <- readLines(sfs_file)
# Extract the second line and split it into individual values
sfs_line <- sfs_lines[2]
sfs_vector <- as.numeric(unlist(strsplit(sfs_line, " ")))
allele_sum = sum(sfs_vector)
# Read the contents of the file into a variable
theta_lines <- readLines(theta_file)
# Extract the fifth line
theta_line <- theta_lines[5]
theta <- as.numeric(regmatches(theta_line, regexpr("\\d+\\.\\d+", theta_line)))
mu_low = 4.08E-10
generations_high = 2 * lowest_tau * theta / (4 * mu_low * allele_sum)
years = 2 * lowest_tau * theta / (4 * 4.08E-10 * allele_sum * 365)
return(years)
}
return_time_mle = function(input, sfs_file, theta_file) {
species_surface = read.csv(input, header=TRUE)
names(species_surface) = c('index', 'nu', 'tau', 'likelihood')
species_surface = species_surface[order(species_surface$likelihood, decreasing=TRUE), ]
mle_tau = species_surface$tau[i]
# Read the contents of the file into a variable
sfs_lines <- readLines(sfs_file)
# Extract the second line and split it into individual values
sfs_line <- sfs_lines[2]
sfs_vector <- as.numeric(unlist(strsplit(sfs_line, " ")))
allele_sum = sum(sfs_vector)
# Read the contents of the file into a variable
theta_lines <- readLines(theta_file)
# Extract the fifth line
theta_line <- theta_lines[5]
theta <- as.numeric(regmatches(theta_line, regexpr("\\d+\\.\\d+", theta_line)))
mu_low = 4.08E-10
generations_high = 2 * mle_tau * theta / (4 * mu_low * allele_sum)
years = 2 * mle_tau * theta / (4 * 4.08E-10 * allele_sum * 365)
return(years)
}
read_demography_info <- function(filepath) {
# Read the content of the file
file_content <- readLines(filepath)
# Extract the relevant lines
nu <- as.numeric(regmatches(file_content[1], regexpr("\\d+\\.\\d+", file_content[1])))
low_years <- as.numeric(regmatches(file_content[length(file_content)-3], regexpr("\\d+\\.\\d+", file_content[length(file_content)-3])))
low_ancestral_size <- as.numeric(regmatches(file_content[length(file_content)-1], regexpr("\\d+\\.\\d+", file_content[length(file_content)-1])))
# Create a vector with the extracted information
result_vector <- c(nu, low_years, low_ancestral_size)
return(result_vector)
}
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
pchisq(274.376417233, 1, lower.tail=FALSE)
library(ggplot2)
library(ggrepel)
library(ggsignif)
#install.packages("ggpubr")
library(ggpubr)
library(dplyr)
library(fitdistrplus)
library(scales)
library(reshape2)
library(stringr)
library(ggridges)
library(forcats)
library("ggrepel")
library(patchwork)
library(ape)
library(ggtree)
library(treeio)
# install.packages('plotly')
library(plotly)
if (!require("BiocManager", quietly = TRUE))
install.packages("BiocManager")
library(latex2exp)
library(ggvis)
library(pheatmap)
library(ComplexHeatmap)
library(phytools)
# BiocManager::install("ComplexHeatmap")
library(mdthemes)
# BiocManager::install("treeio")
# BiocManager::install("ggtree")
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
options(digits = 15)
data = read.table('../Summary/HighRecombination_species_prevalence.txt', sep=',')
data
names(data) = c('Species', 'Prevalence')
data = data[order(Species, Prevalence), ]
data = data[order(data$Species, data$Prevalence), ]
data
data = data[order(data$Prevalence, data$Species), ]
data
data = data[order(data$Prevalence, -data$Species), ]
data = data[order(Prevalence, -Species), ]
data$Prevalence
data = data[order(data$Prevalence, data$Species), ]
data
data = data[order(-data$Prevalence, data$Species), ]
data
data = top_n(data, 50)
data
plt <- ggplot(data) +
geom_col(aes(y=fct_reorder(V1, V2), x = V2), fill = 'blue', width = 0.6) +
theme_bw() +
xlab('Prevalence in Large Dataset') +
ylab('Species') +
ggtitle('Species Prevalence in Korpela') +
xlim(0, 900)
plt
plt <- ggplot(data) +
geom_col(aes(y=fct_reorder(Species, Prevalence), x = Prevalence), fill = 'blue', width = 0.6) +
theme_bw() +
xlab('Prevalence in Large Dataset') +
ylab('Species') +
ggtitle('Species Prevalence in Korpela') +
xlim(0, 900)
plt
