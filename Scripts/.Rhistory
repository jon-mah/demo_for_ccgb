} else if (species_surface_A$scale[count] != unique_scale_A[j]) {
print('break')
}
count = count + 1
}
}
temp_surface_A = species_surface_A[order(species_surface_A$likelihood, decreasing=TRUE), ]
best_params_A = c(temp_surface_A$shape[1], temp_surface_A$scale[1])
ML_A = temp_surface_A$likelihood[1]
species_surface_B = read.csv(input_B, header=TRUE)
names(species_surface_B) = c('shape', 'scale', 'likelihood')
unique_shape_B = unique(species_surface_B$shape)
unique_scale_B = unique(species_surface_B$scale)
Z_B = matrix(data=NA, nrow=length(unique_shape_B), ncol=length(unique_scale_B))
count = 1
for (i in 1:length(unique_shape_B)) {
for (j in 1:length(unique_scale_B)) {
Z_B[i, j] = species_surface_B$likelihood[count]
if (species_surface_B$shape[count] != unique_shape_B[i]) {
print('break')
} else if (species_surface_B$scale[count] != unique_scale_B[j]) {
print('break')
}
count = count + 1
}
}
temp_surface_B = species_surface_B[order(species_surface_B$likelihood, decreasing=TRUE), ]
best_params_B = c(temp_surface_B$shape[1], temp_surface_B$scale[1])
ML_B = temp_surface_B$likelihood[1]
combined_likelihood = species_surface_A$likelihood + species_surface_B$likelihood
comparison_surface = data.frame(species_surface_A$shape, species_surface_A$scale, combined_likelihood)
temp_comparison_surface = comparison_surface[order(comparison_surface$combined_likelihood, decreasing=TRUE), ]
best_params_comparison = c(temp_comparison_surface$species_surface_A.shape[1], temp_comparison_surface$species_surface_A.scale[1])
ML_comparison = temp_comparison_surface$combined_likelihood[1]
independent_sum = ML_A + ML_B
Lambda = independent_sum - ML_comparison
return(2 * Lambda)
}
compare_core_accessory_sfs = function(all, core, accessory) {
x_axis = 1:length(all)
input_df = data.frame(proportional_sfs(all),
proportional_sfs(core),
proportional_sfs(accessory),
x_axis)
names(input_df) = c('All genes',
'Core genes',
'Accessory genes',
'x_axis')
p_input_comparison <- ggplot(data = melt(input_df, id='x_axis'),
aes(x=x_axis,
y=value,
fill=variable)) +
geom_bar(position='dodge2', stat='identity') +
labs(x = "", fill = "") +
scale_x_continuous(name='Minor allele frequency in sample', breaks=x_axis, limits=c(0.5, length(x_axis) + 0.5)) +
ylab('Proportion of segregating sites') +
theme_bw() + theme(panel.border = element_blank(), panel.grid.major = element_blank(),
panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"))
## scale_fill_manual(values=c("darkslateblue", "darkslategrey", "darkturquoise"))
return(p_input_comparison)
}
compare_core_accessory_sfs_count = function(all, core, accessory) {
x_axis = 1:length(all)
input_df = data.frame(all,
core,
accessory,
x_axis)
names(input_df) = c('All genes',
'Core genes',
'Accessory genes',
'x_axis')
p_input_comparison <- ggplot(data = melt(input_df, id='x_axis'),
aes(x=x_axis,
y=value,
fill=variable)) +
geom_bar(position='dodge2', stat='identity') +
labs(x = "", fill = "") +
scale_x_continuous(name='Minor allele frequency in sample', breaks=x_axis, limits=c(0.5, length(x_axis) + 0.5)) +
ylab('Proportion of segregating sites') +
theme_bw() + theme(panel.border = element_blank(), panel.grid.major = element_blank(),
panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"))
## scale_fill_manual(values=c("darkslateblue", "darkslategrey", "darkturquoise"))
return(p_input_comparison)
}
compare_core_accessory_sfs_syn_ns = function(core_syn, core_nonsyn, accessory_syn, accessory_nonsyn) {
x_axis = 1:length(core_syn)
input_df = data.frame(proportional_sfs(core_syn),
proportional_sfs(core_nonsyn),
proportional_sfs(accessory_syn),
proportional_sfs(accessory_nonsyn),
x_axis)
names(input_df) = c('Core genes (Syn)',
'Core genes (Nonsyn)',
'Accessory genes (Syn)',
'Accessory genes (Nonsyn)',
'x_axis')
p_input_comparison <- ggplot(data = melt(input_df, id='x_axis'),
aes(x=x_axis,
y=value,
fill=variable)) +
geom_bar(position='dodge2', stat='identity') +
labs(x = "", fill = "") +
scale_x_continuous(name='Minor allele frequency in sample', breaks=x_axis, limits=c(0.5, length(x_axis) + 0.5)) +
ylab('Proportion of segregating sites') +
theme_bw() + theme(panel.border = element_blank(), panel.grid.major = element_blank(),
panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"))+
scale_fill_manual(values=c("blue4", "steelblue3", "goldenrod3", "goldenrod1"))
return(p_input_comparison)
}
compare_core_accessory_sfs_syn_ns_5A = function(core_syn, core_nonsyn, accessory_syn, accessory_nonsyn) {
x_axis = 1:length(core_syn)
input_df = data.frame(proportional_sfs(core_syn),
proportional_sfs(core_nonsyn),
proportional_sfs(accessory_syn),
proportional_sfs(accessory_nonsyn),
x_axis)
names(input_df) = c('Core genes (Syn)',
'Core genes (Nonsyn)',
'Accessory genes (Syn)',
'Accessory genes (Nonsyn)',
'x_axis')
p_input_comparison <- ggplot(data = melt(input_df, id='x_axis'),
aes(x=x_axis,
y=value,
fill=variable)) +
geom_bar(position='dodge2', stat='identity') +
labs(x = "", fill = "") +
scale_x_continuous(name='Minor allele frequency in sample', breaks=x_axis, limits=c(0.5, length(x_axis) + 0.5)) +
ylab('Proportion of segregating sites') +
theme_bw() + theme(panel.border = element_blank(), panel.grid.major = element_blank(),
panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"))+
scale_fill_manual(values=c("blue4", "steelblue3", "goldenrod3", "goldenrod1")) +
theme(legend.position = c(0.72, 0.75)) +
theme(plot.title = element_text(face = "italic", size=16)) +
theme(legend.text=element_text(size=10))
return(p_input_comparison)
}
compare_core_accessory_sfs_syn_ns_5B = function(core_syn, core_nonsyn, accessory_syn, accessory_nonsyn) {
x_axis = 1:length(core_syn)
input_df = data.frame(proportional_sfs(core_syn),
proportional_sfs(core_nonsyn),
proportional_sfs(accessory_syn),
proportional_sfs(accessory_nonsyn),
x_axis)
names(input_df) = c('Core genes (Syn)',
'Core genes (Nonsyn)',
'Accessory genes (Syn)',
'Accessory genes (Nonsyn)',
'x_axis')
p_input_comparison <- ggplot(data = melt(input_df, id='x_axis'),
aes(x=x_axis,
y=value,
fill=variable)) +
geom_bar(position='dodge2', stat='identity') +
labs(x = "", fill = "") +
scale_x_continuous(name='Minor allele frequency in sample', breaks=x_axis, limits=c(0.5, length(x_axis) + 0.5)) +
ylab('Proportion of segregating sites') +
theme_bw() + theme(panel.border = element_blank(), panel.grid.major = element_blank(),
panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"))+
scale_fill_manual(values=c("blue4", "steelblue3", "goldenrod3", "goldenrod1")) +
theme(plot.title = element_text(face = "italic", size=16)) +
theme(legend.position='none')
return(p_input_comparison)
}
compare_core_sfs = function(all, core) {
x_axis = 1:length(all)
input_df = data.frame(proportional_sfs(all),
proportional_sfs(core),
x_axis)
names(input_df) = c('All genes',
'Core genes',
'x_axis')
p_input_comparison <- ggplot(data = melt(input_df, id='x_axis'),
aes(x=x_axis,
y=value,
fill=variable)) +
geom_bar(position='dodge2', stat='identity') +
labs(x = "", fill = "") +
scale_x_continuous(name='Minor allele frequency in sample', breaks=x_axis, limits=c(0.5, length(x_axis) + 0.5)) +
ylab('Proportion of segregating sites') +
theme_bw() + theme(panel.border = element_blank(), panel.grid.major = element_blank(),
panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"))
## scale_fill_manual(values=c("darkslateblue", "darkslategrey", "darkturquoise"))
return(p_input_comparison)
}
extract_array_length <- function(input_string) {
array_string <- str_extract(input_string, "\\[(.*?)\\]")
num_elements <- length(strsplit(array_string, "[ ,]")[[1]])
return(num_elements)
}
AIC_from_demography = function(input_file) {
## Reads input SFS from output *demography.txt
if(grepl("one_epoch", input_file)) {
k=2
} else if(grepl("two_epoch", input_file)) {
k=4
} else {
k=8
}
this_file = file(input_file)
on.exit(close(this_file))
ll_string = readLines(this_file)[2]
loglik <- as.numeric(str_extract(ll_string, "-?\\d+\\.\\d+"))
return(k - 2*loglik)
}
theta_from_demography = function(input_file) {
## Returns theta from given *demography.txt
# Read the second line of the file
theta_line <- readLines(input_file, n = 5)[5]
# Extract numeric values using regular expression
theta <- as.numeric(regmatches(theta_line, regexpr("[0-9]+\\.[0-9]+", theta_line)))
return(theta)
}
nanc_from_demography = function(input_file) {
## Returns nanc from given *demography.txt
# Read the second line of the file
nanc_line <- readLines(input_file)[length(readLines(input_file))]
# Extract numeric values using regular expression
nanc <- as.numeric(regmatches(nanc_line, regexpr("[0-9]+\\.[0-9]+", nanc_line)))
return(nanc)
}
return_nu_high = function(input) {
species_surface = read.csv(input, header=TRUE)
names(species_surface) = c('index', 'nu', 'tau', 'likelihood')
MLE = max(species_surface$likelihood)
# Task 1: Remove rows with likelihood less than MLE - 3
species_surface <- species_surface[species_surface$likelihood >= MLE - 3, ]
# Task 2: Get the highest nu value from the remaining rows
highest_nu <- max(species_surface$nu)
return(highest_nu)
}
return_nu_low = function(input) {
species_surface = read.csv(input, header=TRUE)
names(species_surface) = c('index', 'nu', 'tau', 'likelihood')
MLE = max(species_surface$likelihood)
# Task 1: Remove rows with likelihood less than MLE - 3
species_surface <- species_surface[species_surface$likelihood >= MLE - 3, ]
# Task 2: Get the highest nu value from the remaining rows
lowest_nu <- min(species_surface$nu)
return(lowest_nu)
}
return_nu_mle = function(input) {
species_surface = read.csv(input, header=TRUE)
names(species_surface) = c('index', 'nu', 'tau', 'likelihood')
species_surface = species_surface[order(species_surface$likelihood, decreasing=TRUE), ]
return(species_surface$nu[1])
}
return_tau_mle = function(input) {
species_surface = read.csv(input, header=TRUE)
names(species_surface) = c('index', 'nu', 'tau', 'likelihood')
species_surface = species_surface[order(species_surface$likelihood, decreasing=TRUE), ]
return(species_surface$nu[2])
}
return_time_high = function(input, sfs_file, theta_file) {
species_surface = read.csv(input, header=TRUE)
names(species_surface) = c('index', 'nu', 'tau', 'likelihood')
MLE = max(species_surface$likelihood)
# Task 1: Remove rows with likelihood less than MLE - 3
species_surface <- species_surface[species_surface$likelihood >= MLE - 3, ]
# Task 2: Get the highest nu value from the remaining rows
highest_tau <- max(species_surface$tau)
# Read the contents of the file into a variable
sfs_lines <- readLines(sfs_file)
# Extract the second line and split it into individual values
sfs_line <- sfs_lines[2]
sfs_vector <- as.numeric(unlist(strsplit(sfs_line, " ")))
allele_sum = sum(sfs_vector)
# Read the contents of the file into a variable
theta_lines <- readLines(theta_file)
# Extract the fifth line
theta_line <- theta_lines[5]
theta <- as.numeric(regmatches(theta_line, regexpr("\\d+\\.\\d+", theta_line)))
mu_low = 4.08E-10
generations_high = 2 * highest_tau * theta / (4 * mu_low * allele_sum)
years = 2 * highest_tau * theta / (4 * 4.08E-10 * allele_sum * 365)
return(years)
}
return_time_low = function(input, sfs_file, theta_file) {
species_surface = read.csv(input, header=TRUE)
names(species_surface) = c('index', 'nu', 'tau', 'likelihood')
MLE = max(species_surface$likelihood)
# Task 1: Remove rows with likelihood less than MLE - 3
species_surface <- species_surface[species_surface$likelihood >= MLE - 3, ]
# Task 2: Get the highest nu value from the remaining rows
lowest_tau <- min(species_surface$tau)
# Read the contents of the file into a variable
sfs_lines <- readLines(sfs_file)
# Extract the second line and split it into individual values
sfs_line <- sfs_lines[2]
sfs_vector <- as.numeric(unlist(strsplit(sfs_line, " ")))
allele_sum = sum(sfs_vector)
# Read the contents of the file into a variable
theta_lines <- readLines(theta_file)
# Extract the fifth line
theta_line <- theta_lines[5]
theta <- as.numeric(regmatches(theta_line, regexpr("\\d+\\.\\d+", theta_line)))
mu_low = 4.08E-10
generations_high = 2 * lowest_tau * theta / (4 * mu_low * allele_sum)
years = 2 * lowest_tau * theta / (4 * 4.08E-10 * allele_sum * 365)
return(years)
}
return_time_mle = function(input, sfs_file, theta_file) {
species_surface = read.csv(input, header=TRUE)
names(species_surface) = c('index', 'nu', 'tau', 'likelihood')
species_surface = species_surface[order(species_surface$likelihood, decreasing=TRUE), ]
mle_tau = species_surface$tau[i]
# Read the contents of the file into a variable
sfs_lines <- readLines(sfs_file)
# Extract the second line and split it into individual values
sfs_line <- sfs_lines[2]
sfs_vector <- as.numeric(unlist(strsplit(sfs_line, " ")))
allele_sum = sum(sfs_vector)
# Read the contents of the file into a variable
theta_lines <- readLines(theta_file)
# Extract the fifth line
theta_line <- theta_lines[5]
theta <- as.numeric(regmatches(theta_line, regexpr("\\d+\\.\\d+", theta_line)))
mu_low = 4.08E-10
generations_high = 2 * mle_tau * theta / (4 * mu_low * allele_sum)
years = 2 * mle_tau * theta / (4 * 4.08E-10 * allele_sum * 365)
return(years)
}
read_demography_info <- function(filepath) {
# Read the content of the file
file_content <- readLines(filepath)
# Extract the relevant lines
nu <- as.numeric(regmatches(file_content[1], regexpr("\\d+\\.\\d+", file_content[1])))
low_years <- as.numeric(regmatches(file_content[length(file_content)-3], regexpr("\\d+\\.\\d+", file_content[length(file_content)-3])))
low_ancestral_size <- as.numeric(regmatches(file_content[length(file_content)-1], regexpr("\\d+\\.\\d+", file_content[length(file_content)-1])))
# Create a vector with the extracted information
result_vector <- c(nu, low_years, low_ancestral_size)
return(result_vector)
}
compute_selection_coefficients <- function(input_file) {
input_dfe_params = read_dfe_params(input_file)
input_dfe_df = melt(input_dfe_params)
input_dfe_df$value[input_dfe_df$value <= 1e-12] = 1e-12
input_dfe_df$value[input_dfe_df$value >= 1] = 1
input_dfe_df = rbind(
input_dfe_df[input_dfe_df$variable == 'gamma_dfe_dist_low', ],
input_dfe_df[input_dfe_df$variable == 'neugamma_dfe_dist_low',])
input_dfe_df$variable <- as.character(input_dfe_df$variable)
input_dfe_df$variable[input_dfe_df$variable == 'neugamma_dfe_dist_low'] <- 'Neutral + Gamma-Distributed DFE'
input_dfe_df$variable[input_dfe_df$variable == 'gamma_dfe_dist_low'] <- 'Gamma-Distributed DFE'
weakly_deleterious_s =  1E-6
moderately_deleterious_s = 1E-2
lethal_s = 0.5
DFE_cutoffs = c(-Inf, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, Inf)
input_gamma_dfe = input_dfe_df[input_dfe_df$variable=='Gamma-Distributed DFE', ]
input_gamma_dfe[input_gamma_dfe$value < 1e-13, ]= 1e-13
input_gamma_dfe[input_gamma_dfe$value > 1e2, ]= 1e2
input_gamma_dfe_bins = cut(input_gamma_dfe$value, breaks=DFE_cutoffs)
input_mean_s = mean(input_gamma_dfe$value)
input_weakly_deleterious = mean(input_gamma_dfe$value < weakly_deleterious_s)
input_moderately_deleterious =  mean(weakly_deleterious_s < input_gamma_dfe$value & input_gamma_dfe$value < moderately_deleterious_s)
input_highly_deleterious = mean(moderately_deleterious_s < input_gamma_dfe$value & input_gamma_dfe$value < lethal_s)
input_lethal = mean(input_gamma_dfe$value > lethal_s)
return(c(input_mean_s, input_weakly_deleterious, input_moderately_deleterious, input_highly_deleterious, input_lethal))
}
return_demography_params <- function(input_file) {
# Read the line from the input file
line <- readLines(input_file, n = 1)
# Extract the list of floats using regular expressions
matches <- regmatches(line, gregexpr("\\d+\\.\\d+", line))
# Convert the matched strings to numeric values
floats <- as.numeric(matches[[1]])
return(floats)
}
return_demography_likelihood = function(input_file) {
# Read the second line of the file
second_line <- readLines(input_file, n = 2)[2]
# Extract numeric values using regular expression
model_likelihood <- as.numeric(regmatches(second_line, regexpr("-[0-9]+\\.[0-9]+", second_line)))
return(model_likelihood)
}
time_from_demography = function(input_file) {
# Read the content of the file
file_content <- readLines(input_file)
# Extract the relevant lines
years <- as.numeric(regmatches(file_content[length(file_content)-2], regexpr("\\d+\\.\\d+", file_content[length(file_content)-2])))
return(years)
}
return_DFE_params = function(input_file) {
# # Read the first line of the file
fifth_line <- readLines(input_file)[5]
# # Extract numeric values using regular expression
pattern <- "[-+]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?"
matches <- regmatches(fifth_line, gregexpr(pattern, fifth_line, perl = TRUE))[[1]]
if (length(matches) < 2) {
stop("Insufficient number of floats found in the input string.")
}
gamma_params <- numeric(2)
for (i in 1:2) {
gamma_params[i] <- as.numeric(matches[i])
}
twelfth_line <- readLines(input_file)[12]
# Extract numeric values using regular expression
matches <- regmatches(twelfth_line, gregexpr(pattern, twelfth_line, perl = TRUE))[[1]]
if (length(matches) < 3) {
stop("Insufficient number of floats found in the input string.")
}
neugamma_params <- numeric(3)
for (i in 1:3) {
neugamma_params[i] <- as.numeric(matches[i])
}
return_vector = c(
gamma_params[1],
gamma_params[2],
neugamma_params[1],
neugamma_params[2],
neugamma_params[3]
)
return(return_vector)
}
return_DFE_likelihood = function(input_file) {
# Read the second line of the file
second_line <- readLines(input_file)[2]
# Extract numeric values using regular expression
gamma_likelihood <- as.numeric(regmatches(second_line, regexpr("-[0-9]+\\.[0-9]+", second_line)))
# Read the ninth line of the file
ninth_line <- readLines(input_file)[9]
# Extract numeric values using regular expression
neugamma_likelihood <- as.numeric(regmatches(ninth_line, regexpr("-[0-9]+\\.[0-9]+", ninth_line)))
return_vector = c(
gamma_likelihood,
neugamma_likelihood
)
return(return_vector)
}
plot_figure_s9 = function(no_clade_control,
clade_control,
downsample) {
x_axis = 1:(length(no_clade_control))
max_length <- max(length(no_clade_control), length(clade_control), length(downsample))
# Extend the vectors with "0" to make them all the same length
no_clade_control <- c(no_clade_control, rep(0, max_length - length(no_clade_control)))
clade_control <- c(clade_control, rep(0, max_length - length(clade_control)))
downsample <- c(downsample, rep(0, max_length - length(downsample)))
fig_s9_a = plot_empirical_sfs(no_clade_control) +
ggtitle('*Bacteroides vulgatus*, synonymous without clade control') +
md_theme_minimal() +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black"))
fig_s9_c = plot_empirical_sfs(clade_control) +
ggtitle('*Bacteroides vulgatus*, synonymous with clade control') +
md_theme_minimal() +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black"))
fig_s9_e = plot_empirical_sfs(downsample) +
ggtitle('*Bacteroides vulgatus*, synonymous with clade control and downsampling') +
md_theme_minimal() +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
panel.background = element_blank(), axis.line = element_line(colour = "black"))
figure_s9 = fig_s9_a + fig_s9_c + fig_s9_e + plot_layout(ncol=1)
}
get_pangenome_size = function(input_file) {
# Read the last two lines from the file
lines <- readLines(input_file)
# Extract the number of genes from the second to last line
second_to_last_line <- lines[length(lines) - 1]
gene_count <- as.numeric(sub(".*There are (\\d+) genes in the pangenome.*", "\\1", second_to_last_line))
return(gene_count)
}
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
options(digits = 15)
b_vulgatus_orig = fold_sfs(read_input_sfs_original('../Analysis/Bacteroides_vulgatus_57955_downsampled_14/downsampled_syn_sfs.txt'))
plot_empirical_sfs(b_vulgatus_orig)
?rand
randint(1)
?Random
Z<-array(runif(600), c(100,6))
Z
Z<-array(runif(600), c(8,1))
Z
?runif
runit(8)
Z = array(runif(8, min=0.4, max=0.6))
Z
plot_empirical_sfs(b_vulgatus_orig)
plot_empirical_sfs(b_vulgatus_orig) + ggtitle('Original downsampled B. vulgatus SFS')
b_vulgatus_test = Z * b_vulgatus_orig
b_vulgatus_test
b_vulgatus_orig
plot_empirical_sfs(b_vulgatus_test)
compare_sfs_high_recombination = function(original, recombination) {
x_axis = 1:length(original)
input_df = data.frame(original,
recombination,
x_axis)
names(input_df) = c('Original',
'Recombination',
'x_axis')
p_input_comparison <- ggplot(data = melt(input_df, id='x_axis'),
aes(x=x_axis,
y=value,
fill=variable)) +
geom_bar(position='dodge2', stat='identity') +
labs(x = "", fill = "") +
scale_x_continuous(name='Minor allele frequency in sample', breaks=x_axis, limits=c(0.5, length(x_axis) + 0.5)) +
ylab('Proportion of segregating sites') +
theme_bw() + theme(panel.border = element_blank(), panel.grid.major = element_blank(),
panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"))
## scale_fill_manual(values=c("darkslateblue", "darkslategrey", "darkturquoise"))
return(p_input_comparison)
}
compare_sfs_high_recombination(b_vulgatus_orig, b_vulgatus_test)
compare_sfs_high_recombination(proportional_sfs(b_vulgatus_orig), proportional_sfs(b_vulgatus_test)
)
compare_sfs_high_recombination(b_vulgatus_orig, b_vulgatus_test)
compare_sfs_high_recombination(b_vulgatus_orig, b_vulgatus_test) + ylab('Count of segregating sites')
compare_sfs_high_recombination(b_vulgatus_orig, b_vulgatus_test) + ylab('Count of segregating sites') + ggtitle('B. vulgatus SFS comparison')
compare_sfs_high_recombination(proportional_sfs(b_vulgatus_orig), proportional_sfs(b_vulgatus_test)) + ggtitle('B. vulgatus SFS comparison')
